{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MUTAG(188):\n",
      "====================\n",
      "Number of graphs: 188\n",
      "Number of features: 7\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_attr=[38, 4], edge_index=[2, 38], x=[17, 7], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Average node degree: 2.24\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import trange\n",
    "from torch_geometric.datasets import TUDataset\n",
    "%load_ext autoreload\n",
    "\n",
    "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.utils import get_laplacian\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.utils import get_laplacian, to_scipy_sparse_matrix\n",
    "from scipy.linalg import eigh\n",
    "from numpy import array, identity, diagonal, double\n",
    "import math\n",
    "\n",
    "def jacobi(a, iterations = 10): # Jacobi method\n",
    "    \"\"\"\n",
    "     Taken from https://github.com/mateuv/MetodosNumericos/blob/master/python/NumericalMethodsInEngineeringWithPython/jacobi.py\n",
    "     Modified ending condition\n",
    "    \"\"\"\n",
    "    def maxElem(a): # Find largest off-diag. element a[k,l]\n",
    "        n = len(a)\n",
    "        aMax = 0.0\n",
    "        for i in range(n-1):\n",
    "            for j in range(i+1,n):\n",
    "                if abs(a[i,j]) >= aMax:\n",
    "                    aMax = abs(a[i,j])\n",
    "                    k = i; l = j\n",
    "        return aMax,k,l\n",
    " \n",
    "    def rotate(a,p,k,l): # Rotate to make a[k,l] = 0\n",
    "        n = len(a)\n",
    "        aDiff = a[l,l] - a[k,k]\n",
    "        if abs(a[k,l]) < abs(aDiff)*1.0e-36: t = a[k,l]/aDiff\n",
    "        else:\n",
    "            phi = aDiff/(2.0*a[k,l])\n",
    "            t = 1.0/(abs(phi) + math.sqrt(phi**2 + 1.0))\n",
    "            if phi < 0.0: t = -t\n",
    "        c = 1.0/math.sqrt(t**2 + 1.0); s = t*c\n",
    "        tau = s/(1.0 + c)\n",
    "        temp = a[k,l]\n",
    "        a[k,l] = 0.0\n",
    "        a[k,k] = a[k,k] - t*temp\n",
    "        a[l,l] = a[l,l] + t*temp\n",
    "        for i in range(k):      # Case of i < k\n",
    "            temp = a[i,k]\n",
    "            a[i,k] = temp - s*(a[i,l] + tau*temp)\n",
    "            a[i,l] = a[i,l] + s*(temp - tau*a[i,l])\n",
    "        for i in range(k+1,l):  # Case of k < i < l\n",
    "            temp = a[k,i]\n",
    "            a[k,i] = temp - s*(a[i,l] + tau*a[k,i])\n",
    "            a[i,l] = a[i,l] + s*(temp - tau*a[i,l])\n",
    "        for i in range(l+1,n):  # Case of i > l\n",
    "            temp = a[k,i]\n",
    "            a[k,i] = temp - s*(a[l,i] + tau*temp)\n",
    "            a[l,i] = a[l,i] + s*(temp - tau*a[l,i])\n",
    "        for i in range(n):      # Update transformation matrix\n",
    "            temp = p[i,k]\n",
    "            p[i,k] = temp - s*(p[i,l] + tau*p[i,k])\n",
    "            p[i,l] = p[i,l] + s*(temp - tau*p[i,l])\n",
    " \n",
    "    n = len(a)\n",
    "    p = identity(n)*1.0     # Initialize transformation matrix\n",
    "    for i in range(iterations): # Jacobi rotation loop \n",
    "        aMax,k,l = maxElem(a)\n",
    "        rotate(a,p,k,l)\n",
    "    return diagonal(a), p\n",
    "    \n",
    "def atan_threshold(A):\n",
    "    \"\"\"\n",
    "    Computes 2 * arctan(1/A) with A tensor of shape out_features x in_features x N\n",
    "    if an entry is zero, returns exactly 2\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-5\n",
    "\n",
    "    A = torch.where(A > eps, 2.0 * torch.atan(1 / A), 2.0 * torch.ones(A.size()))\n",
    "\n",
    "    return A\n",
    "\n",
    "def Pmul(P, X):\n",
    "    \"\"\"\n",
    "    3D x 2D Tensor multiplication :\n",
    "    tensor P (out x d x in)\n",
    "    tensor X (d x in)\n",
    "    output : (out x d x in)\n",
    "    \"\"\"\n",
    "\n",
    "    Nout = P.size()[0]\n",
    "    d = P.size()[1]\n",
    "    Nin = P.size()[2]\n",
    "\n",
    "    output = torch.zeros(Nout, d, Nin)\n",
    "\n",
    "    for b in range(Nout):\n",
    "        Pslice = P[b, :, :]  # d x in\n",
    "        aux = Pslice * X  # d x in\n",
    "\n",
    "        output[b, :, :] = aux\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class CayleyConv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, r, normalization='sym',\n",
    "                 bias=True, jacobi_iterations=10):\n",
    "        \"\"\"\n",
    "        Cayley Filter Convolutional Layer\n",
    "        Jacobi method for approximate eigen decomposition (default to 10 iterations)\n",
    "        Reference Implementation https://github.com/amoliu/CayleyNet/blob/master/CayleyNet.ipynb\n",
    "        \"\"\"\n",
    "        super(CayleyConv, self).__init__()\n",
    "\n",
    "        assert r > 0\n",
    "        assert normalization in [None, 'sym', 'rw'], 'Invalid normalization'\n",
    "\n",
    "        self.normalization = normalization\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.jacobi_iterations = jacobi_iterations\n",
    "        \n",
    "        self.r = r \n",
    "        self.real_weight = Parameter(torch.Tensor(out_channels, in_channels, r, 1))\n",
    "        self.imag_weight = Parameter(torch.Tensor(out_channels, in_channels, r, 1))\n",
    "        self.h = Parameter(torch.Tensor(out_channels, in_channels))  # zoom parameter\n",
    "        self.c = Parameter(torch.Tensor(out_channels, in_channels, 1))  # coefficients\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.real_weight.size(1))\n",
    "        self.real_weight.data.uniform_(-stdv, stdv)\n",
    "        self.imag_weight.data.uniform_(-stdv, stdv)\n",
    "        self.h.data.uniform_(-stdv, stdv)\n",
    "        self.c.data.uniform_(-stdv, stdv)\n",
    "        zeros(self.bias)\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):        \n",
    "        \"\"\"\n",
    "        Source: https://github.com/WhiteNoyse/SiGCN\n",
    "        \"\"\"\n",
    "        edge_index, edge_weight = get_laplacian(edge_index, edge_weight,\n",
    "                                            self.normalization)\n",
    "        L = to_scipy_sparse_matrix(edge_index, edge_weight)\n",
    "        \n",
    "        (w, U) = jacobi(L.todense(), self.jacobi_iterations)\n",
    "\n",
    "        w = torch.tensor(w)\n",
    "        Ut = torch.tensor(U.transpose(0, 1)).float()\n",
    "        aux = torch.mm(Ut, x)\n",
    "\n",
    "        aux_2 = torch.tensordot(self.h, w, dims=0) \n",
    "        aux_2 = atan_threshold(aux_2)\n",
    "        aux_2 = torch.tensordot(aux_2, torch.arange(1, self.r + 1, dtype=torch.float),\n",
    "                                  dims=0) \n",
    "        \n",
    "        aux_cos = torch.cos(aux_2).transpose(3, 2) \n",
    "        aux_sin = torch.sin(aux_2).transpose(3, 2)\n",
    "        aux_cos = self.real_weight * aux_cos\n",
    "        aux_sin = self.imag_weight * aux_sin\n",
    "\n",
    "        aux_cos = aux_cos - aux_sin\n",
    "        aux_cos = torch.sum(aux_cos, 2).squeeze()  \n",
    "        aux_cos = aux_cos + self.c\n",
    "        aux_cos = aux_cos.transpose(2, 1) \n",
    "\n",
    "        out = Pmul(aux_cos, aux)\n",
    "        out = torch.sum(out, 2).squeeze() \n",
    "        out = out.transpose(0, 1)\n",
    "        output = torch.mm(torch.Tensor(U), out)\n",
    "        output.clamp(min=0)\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, r={}, normalization={})'.format(\n",
    "            self.__class__.__name__, self.in_channels, self.out_channels,\n",
    "            self.r, self.normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import SAGPooling, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = CayleyConv(dataset.num_node_features, hidden_channels, 64)\n",
    "        self.pool = TopKPooling(hidden_channels, ratio=0.9)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "\n",
    "        x, edge_index, _, batch, _, _ =  self.pool(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, batch) \n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:150: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "100%|██████████| 10/10 [00:41<00:00,  4.17s/it]\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "train_dataset = dataset[:150]\n",
    "test_dataset = dataset[150:]\n",
    "model.train()\n",
    "for epoch in trange(10):\n",
    "    for data in train_dataset: \n",
    "        out = model(data.x, data.edge_index) \n",
    "        loss = criterion(out, data.y) \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7631578947368421 test accuracy\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "for data in test_dataset:  # Iterate in batches over the training/test dataset.\n",
    "    out = model(data.x, data.edge_index)  \n",
    "    pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "print(\"{} test accuracy\".format(correct / len(test_dataset)))  # Derive ratio of correct predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
